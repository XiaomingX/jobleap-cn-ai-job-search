
LLMs Persuasion: Linear Probes Uncover Multi-Turn Dynamics, Show Insights on Strategy & Personality

摘要：
本文运用线性探针研究大语言模型（LLMs）在多轮对话中的说服动态。利用认知科学见解训练针对说服不同方面（成功、被说服者人格、说服策略）的探针，发现探针能在样本和数据集层面捕捉说服多方面情况，比基于提示的方法更高效，还揭示了合成和人类数据集上说服轨迹差异、策略与人格关联等，为研究LLMs其他复杂行为提供途径。

### 大语言模型如何进行说服？线性探针可揭示多轮对话中的说服动态

#### 摘要
大语言模型（LLM）已开始展现出影响人类的能力，但我们对这一动态过程的理解有限。近期工作使用线性探针（一种分析模型表示的轻量级工具）来研究LLM的各种技能，如模拟用户情感和政治观点的能力。受此启发，我们应用探针来研究自然多轮对话中的说服动态。我们利用认知科学的见解，针对说服的不同方面训练探针：说服成功、被说服者的人格和说服策略。尽管探针简单，但它们在样本和数据集层面捕捉到了说服的各个方面。例如，探针可以识别对话中被说服者被说服的时刻或整个数据集通常发生说服成功的时刻。我们还发现，除了比昂贵的基于提示的方法更快外，探针在某些设置下（如揭示说服策略时）表现与基于提示的方法相当甚至更优。这表明探针是研究其他复杂行为（如欺骗和操纵）的可行途径，尤其在多轮设置和大规模数据集分析中，基于提示的方法计算效率低下。

#### 1 引言
大语言模型已开始展现出影响用户信念和观点的能力，其效果被认为可与人类沟通者媲美。这种现象称为基于LLM的说服，具有两用性，既可能有令人担忧的用途（如政治定向和传播错误信息），也可能有有益的应用（如教育和治疗）。

尽管有越来越多证据表明LLM对人类有说服影响，但我们缺乏对这种动态在对话中如何发生的基础理解。具体来说，说服作为一种相当抽象的高级行为，通常被研究为具有深厚认知科学基础的固有人类能力。例如，双过程框架（如启发式-系统式模型）认为说服主要归因于信息接收者。其他理论强调发送者的角色或消息内容特征。这些理论有助于为行为研究奠定基础，旨在量化个性和策略等因素对说服成功的交互影响。

利用认知科学文献中的这些见解，我们的目标是更好地理解LLM如何在半自然主义的多轮设置中说服人类。由于多轮对话可能包含大量标记，基于提示的分析对于此目标不可行，因为它需要为每个标记级查询进行昂贵的前向传递。因此，我们使用线性探针，这是NLP研究中的经典工具，常用于提供LLM中各种抽象现象（如情感、空间、时间和政治观点）的标记级见解。通过使用探针，我们可以高效地在更细的粒度（如标记和轮次级别）上分析多轮对话。为了研究说服动态，我们训练了三个专门的探针，分别针对说服的不同方面：总体说服结果、被说服者的人格和修辞策略。与基于提示的方法相比，这种方法允许我们高效地分析说服动态，我们在图3中量化了这一优势。总体而言，我们做出以下贡献：
- 一种使用线性探针分析LLM驱动对话中说服动态的框架。设计轻量级、高效的探针来捕捉说服的关键方面，实现大规模细粒度、轮次级分析。发现这些探针不仅匹配或超过基于提示的方法的性能，还提供显著的计算效率，使其成为大规模说服分析的实用工具。
- 探测说服结果、修辞策略和人格特质。展示在LLM激活上训练的线性探针可以准确识别说服成功或失败发生的位置，检测说服者使用的修辞策略，并估计对话中的被说服者人格。
- 合成和人类数据集上说服轨迹的实证见解。表明说服线索集中在人类对话的中间轮次，但在LLM生成的对话中转移到最后一两个轮次，揭示了自然数据与合成数据中说服展开时间的系统性差异。
- 策略和人格之间的相关性。通过关联探针输出，揭示外向性等特质调节不同修辞策略（如可信度或情感诉求）的有效性，提供LLM可能调整说服策略的细致图景。

#### 2 实验设置
我们有兴趣使用线性探针检测LLM中的说服行为。每个探针执行多类逻辑回归，使用冻结LLM激活上的经验风险最小化训练。具体来说，设$\mathcal{D} = \{(h_{i,j}^{(n)}, y^{(n)})\}_{n=1}^N$，其中$h_{i,j}^{(n)} \in \mathbb{R}^d$，$y^{(n)} \in \{1, \ldots, C\}$是训练集的d维激活和整数标签。i表示残差流层，j表示提取激活的标记索引。我们的线性探针$f_{i,j}: \mathbb{R}^d \to \mathbb{R}^C$计算$f_{i,j}(h_{i,j}) = \text{softmax}(W_{i,j}h_{i,j} + b_{i,j}) \in \Delta_C$，其中$W_{i,j}, b_{i,j}$是可训练权重和偏置，$\Delta_C$是C概率单形。我们使用交叉熵损失目标和梯度下降优化$\theta_{i,j} = \{W_{i,j}, b_{i,j}\}$。

我们在不同对话粒度上应用探针，探索说服、大五人格特质和修辞策略的预测任务。使用GPT-4o生成合成多轮数据训练探针，在DailyPersuasion和PersuasionforGood数据集上评估，训练Llama-3.2-3b的线性探针并与零样本提示基线比较。

#### 3 在多轮LLM对话中识别说服特征
- **从单个样本中探测说服特征**：手动检查数据集示例，显示探针可揭示多轮对话中的各种说服特征。说服探针检测到说服概率的变化；人格探针显示不同人格特质与说服的关联；策略探针捕捉到可信度诉求的时机。
- **特征是否在整个数据集上通用**：分析数据集级行为，说服探针显示不同数据集上说服信号的分布不同；人格探针显示预测人格的混合结果；策略探针表明探针在预测说服策略轨迹上比提示更优。

#### 4 修辞策略和人格对说服的影响
- **能否基于被说服者人格特质检测说服**：系统验证人格特质与说服的关联，发现低宜人性和高神经质与未说服相关。
- **修辞策略和人格之间存在哪些关联**：计算策略和人格特质之间的相关性，发现外向性与情感诉求中度正相关，与可信度诉求中度负相关，且在不同数据集上一致。

#### 5 讨论
应用线性探针理解LLM在多轮对话中的说服方式，发现探针能揭示说服对话的有意义特征，合成数据和人类数据中说服成功的轮次分布不同。探针为研究LLM其他抽象行为提供有前景的途径。

#### 6 局限性和未来工作
聚焦有限策略和人格框架，未来可扩展到更细粒度策略、其他人格模型和其他说服相关行为；测试更大模型变体增强泛化性。

#### 7 潜在风险
工作风险最小，但探针揭示的策略和人格交互效应可能被误用；评估可能放大数据集潜在偏差。

开源地址：无